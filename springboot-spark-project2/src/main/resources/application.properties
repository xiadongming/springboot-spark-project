spring.application.name=limitSentinelApplication
server.port=9123
spring.redis.host=127.0.0.1
spring.redis.port=6379
#spring.redis.password=
spring.redis.database=0

## 配置redis存储session
spring.session.store-type=redis
spring.session.timeout=3600
spring.session.redis.namespace=login_name


# 数据源
spring.shardingsphere.datasource.names=ds0
spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds0.jdbc-url=jdbc:mysql://localhost:3306/ds0?characterEncoding=utf-8&serverTimezone=GMT%2B8
spring.shardingsphere.datasource.ds0.username=root
spring.shardingsphere.datasource.ds0.password=root
# 展示sql打印
spring.shardingsphere.props.sql.show=true
### sharding-jdbc第一种===========start====================
# 分表配置  在t_order0/1/2三张数据表
#spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds0.t_order$->{0..2}
## inline 表达式 （id类型转换 ->  id.longValue() -> user_${id.longValue() % 4}）
#spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id
#spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE
#
## 取模进行分片
#spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id
#spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order$->{order_id % 3}

##sharding-jdbc 第一种-==========-end=================

##sharding-jdbc 第二种-==========start=================

# 分表配置  在t_order0/1/2三张数据表
spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds0.t_order$->{18..19}0000
# inline 表达式 （id类型转换 ->  id.longValue() -> user_${id.longValue() % 4}）
#spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id
#spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE
# 取模进行分片
#声明根据哪个字段进行分片
spring.shardingsphere.sharding.tables.t_order.table-strategy.standard.sharding-column=province_code
#自定义分片规则类
spring.shardingsphere.sharding.tables.t_order.table-strategy.standard.precise-algorithm-class-name=com.itchina.sharding.ShardingConfigAlgorithm

##sharding-jdbc 第二种-==========end=================



##mybatis
mybatis.mapper-locations=classpath:mapper/*.xml
logging.level.com.itchina.mapper.OrderMapper=debug


## sentinel限流,指定控制台地址
spring.cloud.sentinel.transport.dashboard=localhost:8080
spring.cloud.sentinel.transport.port=8719


## ftp 服务相关
#ftp服务器的地址
#spring.ftp.host=192.168.1.124
#ftp服务器的端口号（连接端口号）
#spring.ftp.port=21
#ftp的用户名
#spring.ftp.username=anonymous
#ftp的密码
#spring.ftp.password=
#ftp上传的根目录
#spring.ftp.basePath=/var/ftp/pub
#回显地址
#spring.ftp.httpPath=http://127.0.0.1

##logger日志文件配置
#日志输出级别
logging.level.com.example = trace
# 不指定路径在当前项目下生成springboot.log日志
# 可以指定完整的路径；
logging.path=D:/logs/
#  在控制台输出的日志的格式
logging.pattern.console=%d{yyyy-MM-dd} [%thread] %-5level %logger{50} - %msg%n
# 指定文件中日志输出的格式
logging.pattern.file=%d{yyyy-MM-dd} === [%thread] === %-5level === %logger{50} ==== %msg%n


#============== kafka =================start=============
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=127.0.0.1:9092
#
##=============== provider  =======================
##发生错误后，消息重发的次数。
#spring.kafka.producer.retries=0
#spring.kafka.producer.linger=1
## 每次批量发送消息的数量
##当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
#spring.kafka.producer.batch-size=16384
## 设置生产者内存缓冲区的大小。
#spring.kafka.producer.buffer-memory=33554432
#
## 指定消息key和消息体的编解码方式
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
## acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
## acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
## acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
#spring.kafka.producer.acks=1
## 自定义分区
#spring.kafka.producer.properties.partitioner.class=com.itchina.kafka.MyPartitionRules
### kafka生产者拦截器
#spring.kafka.producer.interceptor.class=com.itchina.kafka.CustomProducerInterceptor
##=============== consumer  =======================
## 指定默认消费者group id
#spring.kafka.consumer.group-id=xuewu
#spring.kafka.consumer.zookeeper.connect=127.0.0.1:2181
## 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
## latest（默认值）在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）
## earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录
#spring.kafka.consumer.auto-offset-reset=earliest
## 是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
#spring.kafka.consumer.enable-auto-commit=false
#spring.kafka.consumer.session.timeout=10000
## 自动提交的时间间隔 在spring boot 2.X 版本中这里采用的是值的类型为Duration 需要符合特定的格式，如1S,1M,2H,5D
#spring.kafka.consumer.auto-commit-interval=10s
## 在侦听器容器中运行的线程数。
#spring.kafka.listener.concurrency=5
##listner负责ack，每调用一次，就立即commit
#spring.kafka.listener.ack-mode=manual_immediate
##spring.kafka.listener.missing-topics-fatal=false
#
## 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#
##============== kafka =================end=============
#
##开发配置为false,避免修改模板还要重启服务器
spring.thymeleaf.cache=false
##配置模板路径，默认是templates，可以不用配置
spring.thymeleaf.prefix=classpath:/templates/
spring.thymeleaf.suffix=.html
spring.thymeleaf.servlet.content-type=text/html
spring.thymeleaf.mode=HTML
##==========security======
spring.security.user.name=admin
spring.security.user.password=admin

##======rocketmq==========
rocketmq.name-server=127.0.0.1:9876
rocketmq.producer.group=producer-demo1



